# -*- coding: utf-8 -*-
"""cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iIO_luhsq3xMQtwHOyRounPWi0dkTM-N
"""

#*********************************
# Classifier: Convolutional Neural Network using Keras
# Author: Manuel Serna-Aguilera
# This program was run using Google Colaboratory
#*********************************

# Import libraries
import cv2
import json
import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers import Dropout
from keras.models import Model
import random
import sys

np.random.seed(0)

# Load the thesis project repo
! git clone https://github.com/ManuelSerna/uark-honors-thesis.git

# Setup
sys.path.append('uark-honors-thesis/project/')
import file_io as f
english = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']
spanish = ['A', 'AA', 'B', 'C', 'D', 'E', 'EE', 'F', 'G', 'H', 'I', 'II', 'J', 'K', 'L', 'M', 'N', 'NN', 'O', 'OO', 'P', 'Q', 'R', 'S', 'T', 'U', 'UU', 'UUU', 'V', 'W', 'X', 'Y', 'Z']
all_letters = spanish
n_train = 80
n_test = 30

#=================================
# Transform Image
'''
Input:
  - letter: letter to query
  - num: number identifier
  - train: flag to tell function to query training or test images
Return:
  - img: m*m (grayscaled, downsized) image
'''
#=================================
def transform(letter='', num=0, train=True):
  #print('{} {}'.format(letter, num))
  
  # Query image if IDing info was given
  img = f.get_img(name=letter, num=num, training=train)

  # Grayscale image
  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  
  # Downscale image to be m*m
  m = 28
  img = cv2.resize(img , (m, m), interpolation = cv2.INTER_CUBIC)
  
  # Get normalized list
  img = img/255.0 # normalize every element
  
  return img

#=================================
# Return Data Set
'''
Input:
  - n: number of samples (either for training and test sets)
  - train: flag to tell function whether to fetch training or test data
Return
  - tuple:
    - data: image data
    - labels: labels to corresponding index in data
'''
#=================================
def get_data(n = -1, train=True):
  num_samples = n * len(all_letters)
  data = np.zeros(shape=(num_samples, 28, 28)) # shape = (n*|all_letters|, 28, 28)
  #labels =  np.chararray(shape=(num_samples,))# (n*|all_letters|,)
  labels = np.zeros(shape=(num_samples,))

  counter = 0
  for l in range(len(all_letters)):
    #print('{}: {}'.format(l, all_letters[l]))
    for num in range(1, n+1):
      data[counter] = transform(all_letters[l], num, train)
      #labels.append(letter)
      labels[counter] = l
      counter += 1
    
  return (data, labels)

# Get training and test data
(X_train, y_train) = get_data(n=n_train, train=True)
(X_test, y_test) = get_data(n=n_test, train=False)

# Check that number of data equals number of labels
assert(X_train.shape[0] == y_train.shape[0]), "The number of images is not equal to the number of labels."
assert(X_train.shape[1:] == (28,28)), "The dimensions of the images are not 28 x 28."
assert(X_test.shape[0] == y_test.shape[0]), "The number of images is not equal to the number of labels."
assert(X_test.shape[1:] == (28,28)), "The dimensions of the images are not 28 x 28."

# Add fourth dim--the number of channels (just 1 for gray)
X_train = X_train.reshape(n_train*len(all_letters), 28, 28, 1)
X_test = X_test.reshape(n_test*len(all_letters), 28, 28, 1)

y_train = to_categorical(y_train, len(all_letters))
y_test = to_categorical(y_test, len(all_letters))

#=================================
# LeNet CNN Model
#=================================
def leNet():
  model = Sequential() # define model using sequential class
  # Start by adding a layer to the model, in this step, insert a convolutional layer.
  '''
  Arg 1: num filters, the more you have, the more computing power needed 
  Arg 2: filter size (of 5x5 for the 28x28 images)
  Arg 3: input will be fed an image that is 28x28 with one channel (greyscale, hence a depth of 1)
  Arg 4: activation function, use the ReLU function
  
  The image will be reduced to 30 feature maps, each 24x24.
  
  Padding works to preserve the spatial dimensionality of the image.
      * Same padding: making the output matrix size the same as the input.
          - Allows to extract low-level features.
  '''
  model.add(Conv2D(30, (5,5), input_shape=(28,28,1), activation='relu')) # use 30 filters of size 5x5
  
  # Add pooling layer
  model.add(MaxPooling2D(pool_size=(2, 2))) # only 1 arg: size of pooling element

  # Add another convolutional layer. Use smaller filter to extract features.
  model.add(Conv2D(15, (3,3), activation='relu')) # have 4,065 parameters, use 15 filters of size 3x3
  
  # Add another pooling layer
  model.add(MaxPooling2D(pool_size=(2, 2))) # produce a 5x5 image with a depth of 50
  
  # Take convoluted data and feed into the fully connected layer
  model.add(Flatten())
  model.add(Dense(500, activation='relu'))
  
  '''
  Use a single dropout layer.
  Although more can be used, and in different places, they are used in between layers that have a high number of parameters, these are more likely to overfit.
  
  Arg 1: fraction rate, the amount of input nodes that the dropout layer drops during each update.
  0 = no nodes dropped.
  1 = all nodes dropped.
  RECOMMENDED = 0.5
  '''
  model.add(Dropout(0.5))
  
  # Define output layer
  model.add(Dense(len(all_letters), activation='softmax'))
  model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])
  
  return model

# Initialize CNN model
model = leNet()
print(model.summary())

# Train network
history = model.fit(X_train, y_train, epochs=10, validation_split=0.1, batch_size=400, verbose=1, shuffle=1)

# Get accuracy of model for current letter set
score = model.evaluate(X_test, y_test, verbose=0)
print(type(score))
print('Test accuracy:', score[1])

# Calculate accuracies for each letter
accuracies = {} # dict to contain accuracy on each letter
confusion = {} # dict to contain all individual classifications

for letter in all_letters:
  matches = []

  # i. Get 30 predictions from CNN for each letter
  for letter_id in range(1, n_test+1):
    # Query image test sample
    img = f.get_img(name=letter, num=letter_id, training=False)

    # Transform image
    img = np.asarray(img)
    img = cv2.resize(img, (28, 28))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = img/255
    img = img.reshape(1, 28, 28, 1)

    # Get best match from model
    prediction = model.predict_classes(img)
    prediction = all_letters[int(prediction)]
    #print("predicted digit: {}".format(prediction))
    matches.append(prediction)
  
  # ii. Add all predictions for a single letter to the dict
  confusion[letter] = matches

  # iii. Compute accuracy of CNN on current letter
  accuracy = 0

  for match in matches:
    if match == letter:
      accuracy += 1
  
  accuracies[letter] = (accuracy/n_test)

# Write dictionary to JSON file
result_file = "results_cnn.json"
confusion_file = "all_best_matches_cnn.json"

with open(result_file, 'w') as file:
    file.write(json.dumps(accuracies, indent=4))

with open(confusion_file, 'w') as file:
    file.write(json.dumps(confusion, indent=4))
  
# In Colaboratory, specify that we want to download our files
from google.colab import files
files.download(result_file)
files.download(confusion_file)
